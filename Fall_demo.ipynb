{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fall demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ISsoB5AIOWyd",
        "Lgl5U8iRRGWj",
        "8RQwNlzTRNbj"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shakthivel-K/oops_proj/blob/main/Fall_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hXRKU4qHNwfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f4f015-ba19-469f-e467-16c56a718f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 36.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 42.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 34.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 5.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=099b3cda0c5afb760da521c0d0bd094d17b94e732ff8ddc2c950d769246ec807\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n",
            "kaggle.json\n",
            "Downloading falldataset.zip to /content\n",
            "100% 12.1G/12.1G [01:43<00:00, 177MB/s]\n",
            "100% 12.1G/12.1G [01:43<00:00, 125MB/s]\n",
            "Archive:  /content/falldataset.zip\n",
            "  inflating: test.tfrecords          \n",
            "  inflating: train.tfrecords         \n",
            "  inflating: validation.tfrecords    \n"
          ]
        }
      ],
      "source": [
        "## Download TFRECORD data\n",
        "import json\n",
        "\n",
        "kaggle = {\"username\":\"manikandan02\",\"key\":\"64d4551e3314adcd54c4f8043eab700a\"}\n",
        "\n",
        "with open('kaggle.json', 'w') as outfile:\n",
        "  json.dump(kaggle,outfile)\n",
        "\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d manikandan02/falldataset\n",
        "!unzip /content/falldataset.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPOBQ9g1L4g4"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YW6xMuptLmpA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import io\n",
        "import time\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "from zipfile import ZipFile\n",
        "import urllib.request as urlreq\n",
        "\n",
        "import imageio\n",
        "import ipywidgets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.compat.v1.keras import backend as k\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,GlobalAveragePooling2D,Dense,Dropout\n",
        "from tensorflow.keras.metrics import Precision, Recall\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eks2e6jcL-Tf"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Set seed value\n",
        "seed_value = 43\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
        "\n",
        "random.seed(seed_value)\n",
        "\n",
        "#numpy seed\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "#Tf seed\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "#Configure new global tensorflow session\n",
        "\n",
        "session_conf = tf.compat.v1.ConfigProto(\n",
        "    intra_op_parallelism_threads = 1,\n",
        "    inter_op_parallelism_threads = 1\n",
        ")\n",
        "\n",
        "sess = tf.compat.v1.Session(graph = tf.compat.v1.get_default_graph(), config = session_conf)\n",
        "k.set_session(sess)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNulEE7VMI4I"
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UAVFUpOgMLro"
      },
      "outputs": [],
      "source": [
        "cfg = {\n",
        "        'frameCount'      :50,\n",
        "        'dataset'         :'CMDFALL & URFD',\n",
        "        'epochs'          :300,\n",
        "        'seed_value'      :43,\n",
        "        'train_split'     :0.7,\n",
        "        'val_split'       :0.2,\n",
        "        'test_split'      :0.1,\n",
        "        'batch_size'      :4,\n",
        "        'optimizer'       :'adam',\n",
        "        'INPUT_SHAPE'     : (50,224,224, 1),\n",
        "        'NUM_CLASSES'     :2,\n",
        "        'LEARNING_RATE'   :1e-4,\n",
        "        'WEIGHT_DECAY'    :1e-5,\n",
        "        'PATCH_SIZE'      :(1,224,224),\n",
        "        'NUM_PATCHES'     : 50, #(50//10)**2,\n",
        "        'LAYER_NORM_EPS'  : 1e-6,\n",
        "        'PROJECTION_DIM'  : 32,\n",
        "        'NUM_HEADS'       : 2,\n",
        "        'NUM_LAYERS'      : 2\n",
        "       }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54zDFr3BN6WE"
      },
      "source": [
        "## Datapipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RBMBNAq7N-hU"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def preprocess(frames: tf.Tensor, label: tf.Tensor):\n",
        "    \"\"\"Preprocess the frames tensors and parse the labels.\"\"\"\n",
        "    # Preprocess images\n",
        "    frames = tf.image.convert_image_dtype(\n",
        "        frames[\n",
        "            ..., tf.newaxis\n",
        "        ],  # The new axis is to help for further processing with Conv3D layers\n",
        "        tf.float32,\n",
        "    )\n",
        "    # Parse label\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    return frames, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3clo16z0OB_M"
      },
      "outputs": [],
      "source": [
        "def parser(record):\n",
        "  keys_to_feature = {\n",
        "      'image_raw' :tf.io.FixedLenFeature([],tf.string),\n",
        "      'label'     : tf.io.FixedLenFeature([],tf.int64)\n",
        "  }\n",
        "\n",
        "  parsed = tf.io.parse_single_example(record, keys_to_feature)\n",
        "  image = tf.io.decode_raw(parsed['image_raw'], tf.uint8)\n",
        "  image = tf.reshape(image, shape=[50,224,224])\n",
        "  image = tf.image.convert_image_dtype(image,tf.float32,)\n",
        "  label = tf.cast(parsed['label'], tf.int16)\n",
        "  return image,label\n",
        "\n",
        "trainloader = tf.data.TFRecordDataset(filenames='train.tfrecords').map(parser, num_parallel_calls=tf.data.AUTOTUNE).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(cfg['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
        "validloader = tf.data.TFRecordDataset(filenames='validation.tfrecords').map(parser, num_parallel_calls=tf.data.AUTOTUNE).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(cfg['batch_size']).prefetch(tf.data.AUTOTUNE)\n",
        "testloader = tf.data.TFRecordDataset(filenames='test.tfrecords').map(parser, num_parallel_calls=tf.data.AUTOTUNE).map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).batch(cfg['batch_size']).prefetch(tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-X0A-s-OUKt"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Referenced for Keras examples"
      ],
      "metadata": {
        "id": "E1V6yeT2R_AN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISsoB5AIOWyd"
      },
      "source": [
        "### Tubelet Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0TmAHl-hREa7"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TubeletEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, patch_size, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.patch_size = patch_size\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=patch_size,\n",
        "            strides=patch_size,\n",
        "            padding=\"VALID\",    \n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'patch_size' : self.patch_size,\n",
        "            'embed_dim'  : self.embed_dim\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lgl5U8iRRGWj"
      },
      "source": [
        "### Positional encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "myOIuhI2RKGC"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        _, num_tokens, _ = input_shape\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_tokens, output_dim=self.embed_dim\n",
        "        )\n",
        "        self.positions = tf.range(start=0, limit=num_tokens, delta=1)\n",
        "        \n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            'embed_dim'  : self.embed_dim\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def call(self, encoded_tokens):\n",
        "        # Encode the positions and add it to the encoded tokens\n",
        "        encoded_positions = self.position_embedding(self.positions)\n",
        "        encoded_tokens = encoded_tokens + encoded_positions\n",
        "        return encoded_tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RQwNlzTRNbj"
      },
      "source": [
        "### ViViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6MlZFDZnY5hL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_vivit_classifier(\n",
        "    tubelet_embedder,\n",
        "    positional_encoder,\n",
        "    input_shape,\n",
        "    transformer_layers,\n",
        "    num_heads,\n",
        "    embed_dim,\n",
        "    layer_norm_eps,\n",
        "    num_classes,\n",
        "):\n",
        "    # Get the input layer\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Create patches.\n",
        "    patches = tubelet_embedder(inputs)\n",
        "    # Encode patches.\n",
        "    encoded_patches = positional_encoder(patches)\n",
        "\n",
        "    # Create multiple layers of the Transformer block.\n",
        "    for _ in range(transformer_layers):\n",
        "        # Layer normalization and MHSA\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim // num_heads, dropout=0.3\n",
        "        )(x1, x1)\n",
        "\n",
        "        # Skip connection\n",
        "        x2 = layers.Add()([attention_output, encoded_patches])\n",
        "\n",
        "        # Layer Normalization and MLP\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        x3 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=embed_dim * 4, activation=tf.nn.gelu),\n",
        "                layers.Dense(units=embed_dim, activation=tf.nn.gelu),\n",
        "            ]\n",
        "        )(x3)\n",
        "\n",
        "        # Skip connection\n",
        "        encoded_patches = layers.Add()([x3, x2])\n",
        "\n",
        "    # Layer normalization and Global average pooling.\n",
        "    representation = layers.LayerNormalization(epsilon=layer_norm_eps)(encoded_patches)\n",
        "    representation = layers.GlobalAvgPool1D()(representation)\n",
        "\n",
        "    # Classify outputs.\n",
        "    outputs = layers.Dense(units=num_classes)(representation)\n",
        "\n",
        "    # Create the Keras model.\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8lPrrOqZXKu"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ELBgV1HyZZBO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dfc3333-d4bb-4425-a265-f73b36282f59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1269/1269 [==============================] - 98s 67ms/step - loss: 0.6943 - accuracy: 0.5613 - val_loss: 0.7362 - val_accuracy: 0.4181 - lr: 1.0000e-04\n",
            "Epoch 2/300\n",
            "1269/1269 [==============================] - 85s 67ms/step - loss: 0.6819 - accuracy: 0.5766 - val_loss: 0.7158 - val_accuracy: 0.4205 - lr: 1.0000e-04\n",
            "Epoch 3/300\n",
            "1269/1269 [==============================] - 199s 157ms/step - loss: 0.6784 - accuracy: 0.5857 - val_loss: 0.7073 - val_accuracy: 0.4346 - lr: 1.0000e-04\n",
            "Epoch 4/300\n",
            "1269/1269 [==============================] - 352s 278ms/step - loss: 0.6763 - accuracy: 0.5879 - val_loss: 0.7024 - val_accuracy: 0.4559 - lr: 1.0000e-04\n",
            "Epoch 5/300\n",
            "1269/1269 [==============================] - 352s 278ms/step - loss: 0.6745 - accuracy: 0.5873 - val_loss: 0.6984 - val_accuracy: 0.5008 - lr: 1.0000e-04\n",
            "Epoch 6/300\n",
            "1269/1269 [==============================] - 352s 277ms/step - loss: 0.6729 - accuracy: 0.5888 - val_loss: 0.6952 - val_accuracy: 0.5102 - lr: 1.0000e-04\n",
            "Epoch 7/300\n",
            " 508/1269 [===========>..................] - ETA: 2:48 - loss: 0.6675 - accuracy: 0.5999"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "def run_experiment():\n",
        "  model = create_vivit_classifier(\n",
        "      tubelet_embedder=TubeletEmbedding(\n",
        "          embed_dim=cfg['PROJECTION_DIM'], patch_size=cfg['PATCH_SIZE']),\n",
        "      positional_encoder=PositionalEncoder(embed_dim=cfg['PROJECTION_DIM']),\n",
        "      input_shape=cfg['INPUT_SHAPE'],\n",
        "      transformer_layers=cfg['NUM_LAYERS'],\n",
        "      num_heads=cfg['NUM_HEADS'],\n",
        "      embed_dim=cfg['PROJECTION_DIM'],\n",
        "      layer_norm_eps=cfg['LAYER_NORM_EPS'],\n",
        "      num_classes=cfg['NUM_CLASSES']\n",
        "  )\n",
        "\n",
        "\n",
        "  # Compile the model with the optimizer, loss function\n",
        "  # and the metrics.\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  model.compile(\n",
        "      optimizer=optimizer,\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[\n",
        "          keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "      ],\n",
        "  )\n",
        "\n",
        "  reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                    factor=0.1,\n",
        "                                                    patience=4,\n",
        "                                                    verbose=1,\n",
        "                                                    cooldown=1)\n",
        "\n",
        "\n",
        "\n",
        "  # Train the model.\n",
        "  _ = model.fit(trainloader, epochs=300, validation_data=validloader, callbacks=[reduce_lr])\n",
        "\n",
        "  _, accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "  print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "  return model\n",
        "\n",
        "model = run_experiment()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "GeHREilSChPS",
        "outputId": "3e9ff105-46d7-4780-bb31-78faf86a4609"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ee2a75499397>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_5_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test accuracy: {round(accuracy * 100, 2)}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow import *\n",
        "from keras import *\n",
        "\n",
        "accuracy, top_5_accuracy = model.evaluate(testloader)\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.save_model('model1',model)"
      ],
      "metadata": {
        "id": "-sSE2MCtRuTb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "c26af099-3b42-4bce-9541-a5dbb5603553"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b355ec1fa9ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'save_model'"
          ]
        }
      ]
    }
  ]
}